{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 为什么正则化可以防止过拟合。L1,L2正则化的区别是什么？为什么L1能产生稀疏解？\n",
    "参考 https://www.jianshu.com/p/5e8d83ddc6db  \n",
    "以L2为例，可以有效的降低参数权重，甚至到0，有可以有效的降低模型复杂度，减弱模型的拟合能力\n",
    "\n",
    "L1,L2正则化的区别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 有哪些常见的损失函数\n",
    "\n",
    "\n",
    "Hinge损失函数。max{0,1-f(x)}  **1 - f(x)和0的较大距离**  \n",
    "\n",
    "Logistic损失函数。 $log_2(1 + exp(-f(x))$  \n",
    "\n",
    "交叉熵 Cross Entropy $-log_2(\\frac{1+f(x)}{2})$  **叉烧鹅 -log2 熵-鹅**  \n",
    "\n",
    "平方损失函数\n",
    "\n",
    "绝对损失函数\n",
    "\n",
    "Huber损失函数 \n",
    "\n",
    "$(f-y)^2 , |f-y| <= \\delta $  \n",
    "$2\\delta|f-y| - \\delta^2,|f-y| > \\delta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 常见的优化算法\n",
    "参考 https://zhuanlan.zhihu.com/p/54192512 \n",
    "\n",
    "1. SGD : 每次朝着梯度的反⽅方向进⾏更更新。  \n",
    "2. Momentum(动量法)：动能积累，每次更更新时候积累 SGD 的更更新⽅方向，也就是每次参数更更新时，不不单单考\n",
    "虑当前的梯度⽅方向，还考虑之前的梯度⽅方向，当然之前的梯度会有⼀一个衰减因⼦子。  \n",
    "3. Adagrad：⾃自动调节学习率⼤大⼩小，对于频繁更更新的参数，学习率⼩小；对于很少更更新的参数，学习率\n",
    "⼤大。怎么判断参数频繁更更新呢？可以为更更新公式设置⼀一个分⺟母：梯度平⽅方累加和的平⽅方根。这样当\n",
    "分⺟母越⼤大，说明之前该参数越频繁更更新，反之则很少更更新。存在问题：当迭代次数多了了之后，由于\n",
    "是累加操作，分⺟母越来越⼤大，学习率会变得⾮非常⼩小，模型更更新会很慢。  \n",
    "4. Adadelta：作为 Adagrad 的拓拓展，是解决学习率消失的问题。在这⾥里里不不会直接叠加之前所有的梯\n",
    "度平⽅方，⽽而是引⼊入了了⼀一个梯度衰退的因⼦子，使得时间久远的梯度对此刻参数更更新的影响会消失。\n",
    "RMSProp 的思想和其类似。  \n",
    "5. Adam：结合 Momentum 和 Adadelta 两种优化算法的优点。对梯度的⼀一阶矩估计（First\n",
    "Moment Estimation，即梯度的均值）和⼆二阶矩估计（Second Moment Estimation，即梯度的未\n",
    "中⼼心化的⽅方差）进⾏行行综合考虑，计算出更更新步⻓长。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Batch Normalization\n",
    "\n",
    "参考 https://www.cnblogs.com/guoyaohua/p/8724433.html\n",
    "\n",
    "**机器器学习领域有个很重要的假设。**就是假设训练数据和测试数据是满⾜相同分布的，这是模型效果的基本保障。\n",
    "\n",
    "**BatchNorm的作⽤用是什么呢？在深度神经⽹网络训练过程中使得每一层神经⽹网络的输入保持相同分布的。**\n",
    "\n",
    "**针对问题。**模型⽐比较深⼊后，输入数据经过很多层的变换，分布发⽣生了很大变化，理论上我们要求数据是独⽴立同分布的，\n",
    "\n",
    "但是⽐较深的层它的输入随着前⾯层参数更新，输⼊的入分布越来越不同，也就是所谓的内部协变量量偏移。 \n",
    "\n",
    "**操作1。**为了缓解这个问题，BN通过在每个batch进行减均值除方差的操作，相当于做**归⼀化**操作，把每层的输⼊入分布拉到0 均值1⽅方差的分布中，缓解内部协变量量偏移的问题。\n",
    "\n",
    "**操作2。**又因为这个操作会损失我们前面的层学到的很多信息，为了减⼩这个损失，**我们再对前⾯面的结果做⼀个线性变换，**让它能恢复⼀部分前⾯面的信息\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 RNN 和 LSTM\n",
    "\n",
    "### 问题5.1 什么是RNN？\n",
    "资料 参考 https://www.cnblogs.com/pinard/p/6509630.html  \n",
    "\n",
    "运动员的打靶游戏。\n",
    "运动员每轮在不同的靶口打靶。\n",
    "1. 武器X升级。每一轮都会武器X给运行员做升级。  \n",
    "2. 隐藏属性H。因为属性看不到所以叫隐藏层H。  \n",
    "3. 子弹发射O。武器会发射一个炮弹这个是O。  \n",
    "4. 打靶效果L。子弹打到靶子上评估打偏的多少用L。  \n",
    "5. 最终评分Y。最终的得分用Y。  \n",
    "6. 依据一轮下来的结果调整。\n",
    "运动员要不断训练，依据打靶的结果，调整自己的方式。\n",
    "\n",
    "### 问题5.2 什么是LSTM Long Short-Term Memory\n",
    "\n",
    "大部分与RNN一致，就是多了 三个门区域。 遗忘、输入、输出、多了一个另一个隐藏状态，C 。\n",
    "刚才的打靶游戏继续。  选手打靶完，进入下一个靶场前，要进行升级。 \n",
    "1. 进入遗忘区域。使用sigmoid射线扫面。对上轮状态h，本轮输入x，一起合成扫描。生成新装备f。  \n",
    "2. 进入输入区域。使用sigmod射线扫描。生成状态i，使用tanh射线扫描，生成a。  \n",
    "3. 影子装备合成。跟随过来的影子C捡起了遗忘区域的新装备f。再施法将 ia合成的装备，一起装在身上。形成了新影子C  \n",
    "4. 进入输出区域。使用sigmoid射线扫描，生成新装备o，但是本人能量耗散，没扫死了。这时新影子复制过来，使用tanh射线扫描 ，结合新装备o，共同生成新的选手 H。  \n",
    "5. 新选手射击。 得到Y。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
