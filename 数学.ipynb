{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何理解特征值和特征向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 如何理解矩阵特征值\n",
    "参考 https://www.zhihu.com/question/21874816/answer/181864044"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 理解：什么是特征值？什么是特征向量？\n",
    "**如果把矩阵看作运动**\n",
    "\n",
    "**特征值就是运动的速度**\n",
    "\n",
    "**特征向量就是运动的方向**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 几何意义\n",
    "向量 $\\overrightarrow{v} 在矩阵A 的作用下，方向不变，只进行 比例为 \\lambda 的伸缩，则称向量 \\overrightarrow{v} 是矩阵A的特征向量 $\n",
    "![Image of Yaktocat](https://pic1.zhimg.com/80/v2-3064249b9e5593e8de34fd704dc72dbc_hd.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 PCA原理详解 \n",
    "参考 https://blog.csdn.net/program_developer/article/details/80632779"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA(Principal Component Analysis)即主成分分析方法.\n",
    "\n",
    "### 问题1：什么是PCA算法，它用的主要思想是什么？\n",
    "\n",
    "是一种使用最广泛的数据降维算法。PCA的主要思想是将n维特征映射到k维上，这k维是全新的正交特征也被称为主成分，是在原有n维特征的基础上重新构造出来的k维特征。\n",
    "\n",
    "### 问题2： PCA的降维的步骤是什么样的？\n",
    "\n",
    "从原始的空间中顺序地找一组相互正交的坐标轴。\n",
    "\n",
    "1) 第一个新坐标轴选择是原始数据中方差最大的方向.\n",
    "\n",
    "2) 第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的.\n",
    "\n",
    "3) 第三个轴是与第1,2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。\n",
    "\n",
    "4) 通过这种方式获得的新的坐标轴，我们发现，大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。\n",
    "\n",
    "### 问题3：我们如何得到这些包含最大差异性的主成分方向呢？\n",
    "\n",
    "通过计算数据矩阵的协方差矩阵，得到协方差矩阵的特征值特征向量，选择特征值最大(即方差最大)的k个特征所对应的特征向量组成的矩阵。\n",
    "这样就可以将数据矩阵转换到新的空间当中，实现数据特征的降维。\n",
    "\n",
    "### 问题4：什么是协方差？和方差区别是什么？怎么获得协方差矩阵？怎么得到协方差矩阵的特征值与特征向量？\n",
    "\n",
    "协方差表示的是两个变量的总体的误差。方差是表示一个变量的误差，方差是协方差的特殊情况。\n",
    "\n",
    "两个变量的协方差为正，那么两个变量的变化趋势一致，即一个变量如果变大，那么这个变量也会变大。\n",
    "\n",
    "两个变量的协方差为负，那么两个变量的变化趋势想反。\n",
    "\n",
    "两个变量的协方差为0，说明两个变量不相关。\n",
    "\n",
    "\n",
    "**得到协方差矩阵的特征值特征向量有两种方法。**\n",
    "\n",
    "有两种实现方法：基于特征值分解协方差矩阵实现PCA算法、基于SVD分解协方差矩阵实现PCA算法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 归一化和标准化的区别\n",
    "\n",
    "归一化(Normalization)。将值域映射到 [0,1],只区域与极值大小。  \n",
    "$x^* = \\frac {x - x_{min}}{x_{max} - x_{min}}$\n",
    "\n",
    "标准化(Standardization)。受变量分布影响，将变量映射成正态分布。z-score标准化。处理后 均值为0，标准差为1，公式：\n",
    "$x^* = \\frac{x-u}{\\delta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
