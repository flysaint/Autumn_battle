{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "## 01 半监督学习\n",
    "## 02 生成模型和判别模型\n",
    "## 03 LR模型\n",
    "## 04 最大熵\n",
    "## 05 信息增益\n",
    "## 06 梯度下降\n",
    "## 07 交叉熵函数求导\n",
    "## 08 softmax函数求导\n",
    "## 09 Sigmod函数与softmax函数的联系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01半监督学习\n",
    "参考 https://www.cnblogs.com/kamekin/p/9683162.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1、什么是半监督学习\n",
    "\n",
    "#### 1.1.1 定义。\n",
    "\n",
    "让学习器不依赖外界交互，自动地利用未标记样本来提升学习性能，就是半监督学习（semi-supervised learning）。\n",
    "\n",
    "半监督学习 假设“相似的样本拥有相似的输出”。\n",
    "\n",
    "#### 1.1.2 分类。\n",
    "\n",
    "纯（pure）半监督学习。假定训练数据中的未标记样本 不是 准备进行预测的数据，\n",
    "\n",
    "直推学习（transductive learning）。假定学习过程中所使用的未标记样本恰是 准备进行预测数据。等于需要使用部分待预测数据，预测这些数据本身。\n",
    "\n",
    "### 1-2、无标记样本的意义\n",
    "\n",
    "有了无标签数据的分布信息后，两个类的分类超平面就变得比较明确了。**因此，使用无标签数据可以提高分类边界的准确性，提高模型的稳健性。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3、伪标签（Pseudo-Labelling）学习\n",
    "\n",
    "#### 1.3.1 定义\n",
    "伪标签学习也叫简单自训练（simple self-training）：用有标签数据训练一个分类器，然后用这个分类器对无标签数据进行分类，\n",
    "\n",
    "这样就会产生伪标签（pseudo label）或软标签（soft label），挑选你认为分类正确的无标签样本（此处应该有一个挑选准则），把选出来的无标签样本用来训练分类器\n",
    "\n",
    "#### 1.3.2 大致步骤\n",
    "\n",
    "1)用有标签数据训练模型；\n",
    "\n",
    "2)用训练的模型为无标签的数据预测标签，即获得无标签数据的伪标签；\n",
    "\n",
    "3)使用(2)获得的伪标签和标签数据集重新训练模型；\n",
    "\n",
    "最终的模型是(3)训练得到，用于对测试数据的最终预测。\n",
    "\n",
    "在实际使用过程中，会在(3)步中增加一个参数：采样比例（sample_rate），表示无标签数据中本用作伪标签样本的比率。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 半监督学习方法 \n",
    "#### 1.4.1 半监督SVM（Semi-Supervised Support Vector Machine,简称S3VM）\n",
    "\n",
    "#### 传统SVM和S3VM的区别\n",
    "有传统SVM试图找到一个划分超平面，使得两侧支持向量之间的间隔最大，即“最大划分间隔”思想。</p>\n",
    "半监督学习，S3VM则考虑超平面需穿过数据低密度的区域。\n",
    "\n",
    "#### TSVM。\n",
    "定义。TSVM是半监督支持向量机中的最著名代表。\n",
    "\n",
    "主要思想。尝试将每个未标记样本分别作为正例或反例，在所有结果中，寻找一个在所有样本上间隔最大的划分超平面。\n",
    "\n",
    "求解步骤。采用局部搜索的策略来进行迭代求解。\n",
    "\n",
    "1) 首先使用有标记样本集训练出一个初始SVM。</p>\n",
    "2) 接着使用该学习器对未标记样本进行标记，这样所有样本都有了标记。 </p>\n",
    "\n",
    "3) 基于这些有标记的样本重新训练SVM，之后再寻找易出错样本不断调整。</p>\n",
    "#### 1.4.2 半监督深度学习 \n",
    "详见参考文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
